{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info_df = pl.read_csv(\"./data/station_information.csv\")\n",
    "daily_rental = pl.read_csv(\"./data/daily_rental_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_info schema: Schema([('short_name', Int64), ('capacity', Int64), ('region_id', Int64), ('station_id', String), ('lon', Float64), ('name', String), ('lat', Float64)])\n",
      "daily_rental schema: Schema([('ride_id', String), ('rideable_type', String), ('started_at', String), ('ended_at', String), ('start_station_name', String), ('start_station_id', Float64), ('end_station_name', String), ('end_station_id', Float64), ('start_lat', Float64), ('start_lng', Float64), ('end_lat', Float64), ('end_lng', Float64), ('member_casual', String)])\n"
     ]
    }
   ],
   "source": [
    "station_df = pl.DataFrame(station_info_df)\n",
    "print(\"station_info schema:\",station_df.schema)\n",
    "\n",
    "daily_rental_df = pl.DataFrame(daily_rental)\n",
    "print(\"daily_rental schema:\",daily_rental_df.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the Null Values in the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 8)\n",
      "┌─────────────┬─────────────┬───────────┬───────────┬─────────────┬────────────┬─────────┬─────────┐\n",
      "│ start_stati ┆ start_stati ┆ start_lat ┆ start_lng ┆ end_station ┆ end_statio ┆ end_lat ┆ end_lng │\n",
      "│ on_name     ┆ on_id       ┆ ---       ┆ ---       ┆ _name       ┆ n_id       ┆ ---     ┆ ---     │\n",
      "│ ---         ┆ ---         ┆ i64       ┆ i64       ┆ ---         ┆ ---        ┆ i64     ┆ i64     │\n",
      "│ i64         ┆ i64         ┆           ┆           ┆ i64         ┆ i64        ┆         ┆         │\n",
      "╞═════════════╪═════════════╪═══════════╪═══════════╪═════════════╪════════════╪═════════╪═════════╡\n",
      "│ 1899774     ┆ 1899774     ┆ 0         ┆ 0         ┆ 1995563     ┆ 1996618    ┆ 0       ┆ 0       │\n",
      "└─────────────┴─────────────┴───────────┴───────────┴─────────────┴────────────┴─────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "def count_nulls(df: pl.DataFrame, columns: list) -> pl.DataFrame:\n",
    "    null_counts = {\n",
    "        col: df[col].null_count() for col in columns\n",
    "    }\n",
    "    return pl.DataFrame([null_counts])\n",
    "\n",
    "# Example usage\n",
    "columns_to_check = [\n",
    "    \"start_station_name\", \"start_station_id\", \"start_lat\", \"start_lng\",\n",
    "    \"end_station_name\", \"end_station_id\", \"end_lat\", \"end_lng\"\n",
    "]\n",
    "\n",
    "# Assuming your DataFrame is named `daily_rental`\n",
    "nulls_df = count_nulls(daily_rental, columns_to_check)\n",
    "\n",
    "print(nulls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_996_618, 4)\n",
      "┌──────────────────┬────────────────┬─────────┬─────────┐\n",
      "│ end_station_name ┆ end_station_id ┆ end_lat ┆ end_lng │\n",
      "│ ---              ┆ ---            ┆ ---     ┆ ---     │\n",
      "│ str              ┆ f64            ┆ f64     ┆ f64     │\n",
      "╞══════════════════╪════════════════╪═════════╪═════════╡\n",
      "│ null             ┆ null           ┆ 38.92   ┆ -77.01  │\n",
      "│ null             ┆ null           ┆ 38.89   ┆ -77.1   │\n",
      "│ null             ┆ null           ┆ 38.95   ┆ -77.08  │\n",
      "│ null             ┆ null           ┆ 38.9    ┆ -76.99  │\n",
      "│ null             ┆ null           ┆ 38.9    ┆ -77.0   │\n",
      "│ …                ┆ …              ┆ …       ┆ …       │\n",
      "│ null             ┆ null           ┆ 38.89   ┆ -76.98  │\n",
      "│ null             ┆ null           ┆ 38.93   ┆ -77.04  │\n",
      "│ null             ┆ null           ┆ 38.91   ┆ -77.05  │\n",
      "│ null             ┆ null           ┆ 38.91   ┆ -77.03  │\n",
      "│ null             ┆ null           ┆ 38.92   ┆ -77.01  │\n",
      "└──────────────────┴────────────────┴─────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with null values in end_station_name or end_station_id\n",
    "null_rows = daily_rental.filter(\n",
    "    pl.col(\"end_station_name\").is_null() | pl.col(\"end_station_id\").is_null()\n",
    ")\n",
    "\n",
    "# Print the rows with null values\n",
    "print(null_rows.select('end_station_name','end_station_id','end_lat','end_lng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_rental' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Round the latitude and longitude to 4 decimal places\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m daily_rental \u001b[38;5;241m=\u001b[39m \u001b[43mdaily_rental\u001b[49m\u001b[38;5;241m.\u001b[39mwith_columns([\n\u001b[0;32m      3\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_lng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_lng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m station_info \u001b[38;5;241m=\u001b[39m station_df\u001b[38;5;241m.\u001b[39mwith_columns([\n\u001b[0;32m      8\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation_lat\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      9\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation_lng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily_rental' is not defined"
     ]
    }
   ],
   "source": [
    "# Round the latitude and longitude to 4 decimal places\n",
    "daily_rental = daily_rental.with_columns([\n",
    "    pl.col(\"end_lat\").round(2).alias(\"end_lat\"),\n",
    "    pl.col(\"end_lng\").round(2).alias(\"end_lng\")\n",
    "])\n",
    "\n",
    "station_info = station_df.with_columns([\n",
    "    pl.col(\"lat\").round(2).alias(\"station_lat\"),\n",
    "    pl.col(\"lon\").round(2).alias(\"station_lng\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (18_007_247, 25)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ ride_id   ┆ rideable_ ┆ started_a ┆ ended_at  ┆ … ┆ station_i ┆ name_righ ┆ station_l ┆ station_ │\n",
      "│ ---       ┆ type      ┆ t         ┆ ---       ┆   ┆ d_right   ┆ t         ┆ at        ┆ lng      │\n",
      "│ str       ┆ ---       ┆ ---       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│           ┆ str       ┆ str       ┆           ┆   ┆ str       ┆ str       ┆ f64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ C04E20007 ┆ docked_bi ┆ 2020-12-0 ┆ 2020-12-0 ┆ … ┆ 08250172- ┆ 18th St & ┆ null      ┆ null     │\n",
      "│ D039277   ┆ ke        ┆ 2         ┆ 2         ┆   ┆ 1f3f-11e7 ┆ Pennsylva ┆           ┆          │\n",
      "│           ┆           ┆ 09:10:36  ┆ 09:24:12  ┆   ┆ -bf6b-386 ┆ nia Ave   ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆ 3bb…      ┆ NW        ┆           ┆          │\n",
      "│ A488C0D9F ┆ classic_b ┆ 2020-12-3 ┆ 2020-12-3 ┆ … ┆ 082623bf- ┆ 17th St & ┆ null      ┆ null     │\n",
      "│ 4761D06   ┆ ike       ┆ 1         ┆ 1         ┆   ┆ 1f3f-11e7 ┆ Independe ┆           ┆          │\n",
      "│           ┆           ┆ 12:46:29  ┆ 14:01:07  ┆   ┆ -bf6b-386 ┆ nce Ave   ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆ 3bb…      ┆ SW        ┆           ┆          │\n",
      "│ 9E7E97A92 ┆ classic_b ┆ 2020-12-3 ┆ 2020-12-3 ┆ … ┆ 082623bf- ┆ 17th St & ┆ null      ┆ null     │\n",
      "│ 7A85552   ┆ ike       ┆ 1         ┆ 1         ┆   ┆ 1f3f-11e7 ┆ Independe ┆           ┆          │\n",
      "│           ┆           ┆ 12:47:03  ┆ 14:01:04  ┆   ┆ -bf6b-386 ┆ nce Ave   ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆ 3bb…      ┆ SW        ┆           ┆          │\n",
      "│ 565C5C331 ┆ classic_b ┆ 2020-12-2 ┆ 2020-12-2 ┆ … ┆ 08247269- ┆ S Glebe   ┆ null      ┆ null     │\n",
      "│ ABAD77B   ┆ ike       ┆ 9         ┆ 9         ┆   ┆ 1f3f-11e7 ┆ Rd &      ┆           ┆          │\n",
      "│           ┆           ┆ 13:50:51  ┆ 14:12:22  ┆   ┆ -bf6b-386 ┆ Potomac   ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆ 3bb…      ┆ Ave       ┆           ┆          │\n",
      "│ 7576B3F4B ┆ classic_b ┆ 2020-12-2 ┆ 2020-12-2 ┆ … ┆ 082520aa- ┆ Virginia  ┆ null      ┆ null     │\n",
      "│ 4D6ADFF   ┆ ike       ┆ 7         ┆ 7         ┆   ┆ 1f3f-11e7 ┆ Square    ┆           ┆          │\n",
      "│           ┆           ┆ 12:30:28  ┆ 12:36:12  ┆   ┆ -bf6b-386 ┆ Metro /   ┆           ┆          │\n",
      "│           ┆           ┆           ┆           ┆   ┆ 3bb…      ┆ Monroe…   ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ E530BA648 ┆ electric_ ┆ 2024-11-1 ┆ 2024-11-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 701560A   ┆ bike      ┆ 8 07:40:3 ┆ 8 08:08:1 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 8.653     ┆ 5.542     ┆   ┆           ┆           ┆           ┆          │\n",
      "│ D5752897D ┆ electric_ ┆ 2024-11-1 ┆ 2024-11-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 58E2CCC   ┆ bike      ┆ 2 16:13:1 ┆ 2 16:23:2 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 1.102     ┆ 9.656     ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 69294E4C8 ┆ electric_ ┆ 2024-11-1 ┆ 2024-11-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 958A8EF   ┆ bike      ┆ 5 19:34:1 ┆ 5 19:38:1 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 6.506     ┆ 9.100     ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 8798FC5FB ┆ electric_ ┆ 2024-11-1 ┆ 2024-11-1 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ E03EC63   ┆ bike      ┆ 6 10:08:4 ┆ 6 10:12:0 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 9.577     ┆ 7.244     ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 62417D1E7 ┆ electric_ ┆ 2024-11-0 ┆ 2024-11-0 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 73A1AB1   ┆ bike      ┆ 8 15:45:0 ┆ 8 15:58:3 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 7.334     ┆ 2.711     ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Perform the join on lat/lng coordinates with suffixes to avoid renaming conflicts\n",
    "daily_rental = daily_rental.join(\n",
    "    station_info,\n",
    "    left_on=[\"end_lat\", \"end_lng\"],\n",
    "    right_on=[\"lat\", \"lon\"],\n",
    "    how=\"left\",\n",
    "    suffix=\"_station_info\"  # Custom suffix for the columns from station_info\n",
    ")\n",
    "\n",
    "# Now, correctly use the column names from `station_info` (e.g., 'name' instead of 'station_name')\n",
    "daily_rental = daily_rental.with_columns([\n",
    "    pl.when(pl.col(\"end_station_name\").is_null())\n",
    "      .then(pl.col(\"name_station_info\"))  # Updated to the renamed column\n",
    "      .otherwise(pl.col(\"end_station_name\"))\n",
    "      .alias(\"end_station_name\"),\n",
    "    \n",
    "    pl.when(pl.col(\"end_station_id\").is_null())\n",
    "      .then(pl.col(\"station_id_station_info\"))  # Updated to the renamed column\n",
    "      .otherwise(pl.col(\"end_station_id\"))\n",
    "      .alias(\"end_station_id\")\n",
    "])\n",
    "\n",
    "# Drop unnecessary columns after the join (if any)\n",
    "daily_rental = daily_rental.drop([col for col in daily_rental.columns if \"_station_info\" in col])\n",
    "\n",
    "# Check the result\n",
    "print(daily_rental)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 8)\n",
      "┌────────────┬────────────┬───────────┬───────────┬────────────┬───────────┬───────────┬───────────┐\n",
      "│ start_stat ┆ start_stat ┆ start_lat ┆ start_lng ┆ end_statio ┆ end_stati ┆ end_lat   ┆ end_lng   │\n",
      "│ ion_name   ┆ ion_id     ┆ ---       ┆ ---       ┆ n_name     ┆ on_id     ┆ ---       ┆ ---       │\n",
      "│ ---        ┆ ---        ┆ f64       ┆ f64       ┆ ---        ┆ ---       ┆ f64       ┆ f64       │\n",
      "│ str        ┆ str        ┆           ┆           ┆ str        ┆ str       ┆           ┆           │\n",
      "╞════════════╪════════════╪═══════════╪═══════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32900     ┆ 38.964406 ┆ -77.01075 │\n",
      "│ Tech       ┆            ┆           ┆           ┆ BX Tech    ┆           ┆           ┆ 9         │\n",
      "│ Office     ┆            ┆           ┆           ┆ office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "│ Motivate   ┆ 32902      ┆ null      ┆ null      ┆ Motivate   ┆ 32902     ┆ null      ┆ null      │\n",
      "│ Tech       ┆            ┆           ┆           ┆ Tech       ┆           ┆           ┆           │\n",
      "│ Office     ┆            ┆           ┆           ┆ Office     ┆           ┆           ┆           │\n",
      "└────────────┴────────────┴───────────┴───────────┴────────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "daily_rental_check = daily_rental.with_columns(\n",
    "    pl.when(\n",
    "        ((pl.col(\"start_lat\").is_null())&(pl.col(\"start_lat\").is_null()))|\n",
    "        ((pl.col(\"end_lat\").is_null())&(pl.col(\"end_lat\").is_null()))\n",
    "        )\n",
    "    .then(\n",
    "        daily_rental.with_columns(\n",
    "            pl.when(\n",
    "                ((pl.col(\"start_lat\").is_null())&(pl.col(\"start_lat\").is_null()))|\n",
    "                ((pl.col(\"end_lat\").is_null())&(pl.col(\"end_lat\").is_null()))\n",
    "                )\n",
    "        )\n",
    "    )\n",
    "    .otherwise(0)\n",
    "    .alias('check')\n",
    ")\n",
    "\n",
    "print(daily_rental_check.filter(pl.col(\"check\")==1).select('start_station_name','start_station_id','start_lat','start_lng','end_station_name','end_station_id','end_lat','end_lng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_rental columns: ['ride_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n",
      "station_info columns: ['short_name', 'capacity', 'region_id', 'station_id', 'lon', 'name', 'lat']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily_rental columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, daily_rental\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstation_info columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, station_info_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdaily_rental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m station_info_df\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[1;32md:\\OneDrive\\Desktop\\Test\\.venv\\lib\\site-packages\\polars\\dataframe\\frame.py:5186\u001b[0m, in \u001b[0;36mDataFrame.describe\u001b[1;34m(self, percentiles, interpolation)\u001b[0m\n\u001b[0;32m   5183\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot describe a DataFrame that has no columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m-> 5186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\n\u001b[0;32m   5188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive\\Desktop\\Test\\.venv\\lib\\site-packages\\polars\\lazyframe\\frame.py:983\u001b[0m, in \u001b[0;36mLazyFrame.describe\u001b[1;34m(self, percentiles, interpolation)\u001b[0m\n\u001b[0;32m    962\u001b[0m     metric_exprs\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m    963\u001b[0m         [\n\u001b[0;32m    964\u001b[0m             \u001b[38;5;241m*\u001b[39mcount_exprs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    970\u001b[0m         ]\n\u001b[0;32m    971\u001b[0m     )\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# calculate requested metrics in parallel, then collect the result\u001b[39;00m\n\u001b[0;32m    974\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    975\u001b[0m     \u001b[43m(\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# if more than one quantile, sort the relevant columns to make them O(1)\u001b[39;49;00m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO: drop sort once we have efficient retrieval of multiple quantiles\u001b[39;49;00m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msort_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msort_cols\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_exprs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m--> 983\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m )\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# reshape wide result\u001b[39;00m\n\u001b[0;32m    987\u001b[0m n_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(metrics)\n",
      "File \u001b[1;32md:\\OneDrive\\Desktop\\Test\\.venv\\lib\\site-packages\\polars\\lazyframe\\frame.py:2043\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2042\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "daily_rental = daily_rental.with_columns([\n",
    "    pl.col(\"start_station_id\").cast(pl.Int64),  # Cast to string\n",
    "    pl.col(\"end_station_id\").cast(pl.Int64)      # Cast to string\n",
    "])\n",
    "\n",
    "daily_rental = daily_rental.with_columns([\n",
    "    pl.col(\"start_station_id\").cast(pl.Utf8).alias(\"start_station_id\"),\n",
    "    pl.col(\"end_station_id\").cast(pl.Utf8).alias(\"end_station_id\")\n",
    "])\n",
    "\n",
    "station_info = station_info_df.select([\n",
    "    pl.col(\"short_name\"),\n",
    "    pl.col(\"name\").alias(\"station_name\"),\n",
    "    pl.col(\"lat\").alias(\"station_lat\"),\n",
    "    pl.col(\"lon\").alias(\"station_lng\")\n",
    "])\n",
    "\n",
    "print(\"daily_rental columns:\", daily_rental.columns)\n",
    "print(\"station_info columns:\", station_info_df.columns)\n",
    "\n",
    "daily_rental.describe()\n",
    "station_info_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_station_id_by_lat_lng(df, station_info_df):\n",
    "    \"\"\"\n",
    "    Fill missing station_id using latitude and longitude.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame containing rental data.\n",
    "        station_info_df (pl.DataFrame): DataFrame containing station information.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Updated DataFrame with missing station_id filled.\n",
    "    \"\"\"\n",
    "    # Join by lat and lon and update the start_station_id and end_station_id\n",
    "    df = df.join(station_info_df, left_on=[\"start_lat\", \"start_lng\"], right_on=[\"lat\", \"lon\"], how=\"left\") \\\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(\"start_station_id\").is_null())\n",
    "              .then(pl.col(\"short_name\"))\n",
    "              .otherwise(pl.col(\"start_station_id\"))\n",
    "              .alias(\"start_station_id\"),\n",
    "\n",
    "            pl.when(pl.col(\"end_station_id\").is_null())\n",
    "              .then(pl.col(\"short_name\"))\n",
    "              .otherwise(pl.col(\"end_station_id\"))\n",
    "              .alias(\"end_station_id\")\n",
    "        ]) \\\n",
    "        .select([col for col in df.columns if col not in [\"lat\", \"lon\", \"short_name\"]])  # Drop unnecessary columns\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_station_id_by_name(df, station_name_dict):\n",
    "    \"\"\"\n",
    "    Fill missing station_id using station_name.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame containing rental data.\n",
    "        station_name_dict (dict): Dictionary mapping station_name -> station_id.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Updated DataFrame with missing station_id filled.\n",
    "    \"\"\"\n",
    "    # Use the map function to fill missing values based on station_name\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"start_station_id\").is_null())\n",
    "          .then(pl.col(\"start_station_name\").map(lambda x: station_name_dict.get(x, None), return_dtype=pl.Int64))\n",
    "          .otherwise(pl.col(\"start_station_id\"))\n",
    "          .alias(\"start_station_id\"),\n",
    "        \n",
    "        pl.when(pl.col(\"end_station_id\").is_null())\n",
    "          .then(pl.col(\"end_station_name\").map(lambda x: station_name_dict.get(x, None), return_dtype=pl.Int64))\n",
    "          .otherwise(pl.col(\"end_station_id\"))\n",
    "          .alias(\"end_station_id\")\n",
    "    ])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_station_name_by_id(df, station_id_dict):\n",
    "    \"\"\"\n",
    "    Fill missing station_name using station_id.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame containing rental data.\n",
    "        station_id_dict (dict): Dictionary mapping station_id -> station_name.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Updated DataFrame with missing station_name filled.\n",
    "    \"\"\"\n",
    "    # Use the map function to fill missing values based on station_id\n",
    "    df = df.with_columns([\n",
    "        pl.when(pl.col(\"start_station_name\").is_null())\n",
    "          .then(pl.col(\"start_station_id\").map(lambda x: station_id_dict.get(x, None), return_dtype=pl.Utf8))\n",
    "          .otherwise(pl.col(\"start_station_name\"))\n",
    "          .alias(\"start_station_name\"),\n",
    "        \n",
    "        pl.when(pl.col(\"end_station_name\").is_null())\n",
    "          .then(pl.col(\"end_station_id\").map(lambda x: station_id_dict.get(x, None), return_dtype=pl.Utf8))\n",
    "          .otherwise(pl.col(\"end_station_name\"))\n",
    "          .alias(\"end_station_name\")\n",
    "    ])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming `daily_rental` is your Polars DataFrame and the dictionaries are defined\u001b[39;00m\n\u001b[0;32m      2\u001b[0m daily_rental \u001b[38;5;241m=\u001b[39m fill_station_id_by_lat_lng(daily_rental, station_info_df)\n\u001b[1;32m----> 3\u001b[0m daily_rental \u001b[38;5;241m=\u001b[39m \u001b[43mfill_station_id_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_rental\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation_name_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m daily_rental \u001b[38;5;241m=\u001b[39m fill_station_name_by_id(daily_rental, station_id_dict)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save the updated DataFrame to a CSV file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mfill_station_id_by_name\u001b[1;34m(df, station_name_dict)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mFill missing station_id using station_name.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    pl.DataFrame: Updated DataFrame with missing station_id filled.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Use the map function to fill missing values based on station_name\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns([\n\u001b[0;32m     14\u001b[0m     pl\u001b[38;5;241m.\u001b[39mwhen(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_null())\n\u001b[1;32m---> 15\u001b[0m       \u001b[38;5;241m.\u001b[39mthen(\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart_station_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: station_name_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m), return_dtype\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mInt64))\n\u001b[0;32m     16\u001b[0m       \u001b[38;5;241m.\u001b[39motherwise(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     17\u001b[0m       \u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     18\u001b[0m     \n\u001b[0;32m     19\u001b[0m     pl\u001b[38;5;241m.\u001b[39mwhen(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mis_null())\n\u001b[0;32m     20\u001b[0m       \u001b[38;5;241m.\u001b[39mthen(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_station_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: station_name_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m), return_dtype\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mInt64))\n\u001b[0;32m     21\u001b[0m       \u001b[38;5;241m.\u001b[39motherwise(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     22\u001b[0m       \u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_station_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m ])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "# Assuming `daily_rental` is your Polars DataFrame and the dictionaries are defined\n",
    "daily_rental = fill_station_id_by_lat_lng(daily_rental, station_info_df)\n",
    "daily_rental = fill_station_id_by_name(daily_rental, station_name_dict)\n",
    "daily_rental = fill_station_name_by_id(daily_rental, station_id_dict)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "daily_rental.write_csv('daily_rental_updated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the updated DataFrame to a CSV file\n",
    "# daily_rental.write_csv(\"daily_rental_updated.csv\")\n",
    "\n",
    "# # OR Save to a Parquet file (more efficient for large datasets)\n",
    "# daily_rental.write_parquet(\"daily_rental_updated.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
